{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:34:08.394821Z",
     "start_time": "2022-02-27T08:34:07.731325Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:34:09.669148Z",
     "start_time": "2022-02-27T08:34:09.470023Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:34:11.686169Z",
     "start_time": "2022-02-27T08:34:11.563717Z"
    }
   },
   "outputs": [],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:34:15.088489Z",
     "start_time": "2022-02-27T08:34:11.779333Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import pprint\n",
    "import shutil\n",
    "import zipfile\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mpl.style.use(\"seaborn\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import onnx\n",
    "import tensorflow as tf\n",
    "from onnx_tf.backend import prepare\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "plt.rcParams.update({\"figure.max_open_warning\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check GPU available for tf\n",
    "print(tf.config.experimental.list_physical_devices())\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is cuda available: {}\".format(torch.cuda.is_available()))\n",
    "current_device_id = torch.cuda.current_device()\n",
    "device_info = torch.cuda.device(current_device_id)\n",
    "devices_count = torch.cuda.device_count()\n",
    "device_name = torch.cuda.get_device_name(0)\n",
    "print(\n",
    "    \"Current device id is {} (there are {} devices in total)\\ndevice info: {}\\ndevice name: {}\".format(\n",
    "        current_device_id, devices_count, device_info, device_name, device_name\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:34:23.109828Z",
     "start_time": "2022-02-27T08:34:23.106223Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS_COUNT = 18\n",
    "NUM_WORKERS = 16\n",
    "\n",
    "IMAGE_CROP_WIDTH = 160\n",
    "IMAGE_CROP_HEIGHT = 256\n",
    "\n",
    "train_dir = \"train\"\n",
    "val_dir = \"val\"\n",
    "\n",
    "class_names = [\n",
    "    \"dab_left\",\n",
    "    \"dab_right\",\n",
    "    \"lottery_1\",\n",
    "    \"lottery_2_left\",\n",
    "    \"lottery_2_right\",\n",
    "    \"say_so_1_left\",\n",
    "    \"say_so_1_right\",\n",
    "    \"wap_1_left\",\n",
    "    \"wap_1_right\",\n",
    "    \"wap_2\",\n",
    "    \"wap_3_left\",\n",
    "    \"wap_3_right\",\n",
    "    \"wap_4_left\",\n",
    "    \"wap_4_right\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_NAME = \"dancer\"\n",
    "SUMBISSION_FILE_NAME = \"submission\"\n",
    "\n",
    "PB_PATH = \"./{}.pb\".format(MODEL_SAVE_NAME)\n",
    "TF_PATH = \"./{}.tflite\".format(MODEL_SAVE_NAME)\n",
    "\n",
    "# --- DATASET ---\n",
    "\n",
    "DATASET_DIR = \"/data1/dataset\"\n",
    "\n",
    "# Train dataset\n",
    "BOUNCED_DATASET_ZIP_DIR = \"/data1/dataset/dataset_bounced.zip\"\n",
    "BOUNCED_DATASET_WORKING_DIR = \"/data1/working_dataset_bounced/\"\n",
    "\n",
    "# Test dataset\n",
    "TEST_DATASET_ZIP_DIR = \"/data1/dataset/test_dataset.zip\"\n",
    "TEST_DATASET_WORKING_DIR = \"/data1/working_dataset_bounced/\"\n",
    "\n",
    "# Dataset working dirs\n",
    "DATA_ROOT = \"/data1/working_dataset_bounced/dataset_bounced/\"\n",
    "TEST_DIR = \"/data1/working_dataset_bounced/test/\"\n",
    "\n",
    "# --- PLOTS ---\n",
    "RESULT_PLOTS_DIR = \"plots\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:34:26.696516Z",
     "start_time": "2022-02-27T08:34:26.693448Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(os.listdir(DATASET_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:34:31.764531Z",
     "start_time": "2022-02-27T08:34:31.760849Z"
    }
   },
   "outputs": [],
   "source": [
    "result_plots_dir_check = \"./{}\".format(RESULT_PLOTS_DIR)\n",
    "confusion_matrix_plots_dir = \"confusion_matrix\"\n",
    "confusion_matrix_plots_dir_check = \"./{}/{}\".format(\n",
    "    RESULT_PLOTS_DIR, confusion_matrix_plots_dir\n",
    ")\n",
    "\n",
    "if not os.path.isdir(result_plots_dir_check):\n",
    "    os.makedirs(result_plots_dir_check)\n",
    "if not os.path.isdir(confusion_matrix_plots_dir_check):\n",
    "    os.makedirs(confusion_matrix_plots_dir_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T06:04:08.503146Z",
     "start_time": "2022-02-03T05:40:22.328841Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(BOUNCED_DATASET_ZIP_DIR, \"r\") as zip_obj:\n",
    "    for member in tqdm(zip_obj.infolist(), desc=\"Extracting \"):\n",
    "        try:\n",
    "            zip_obj.extract(member, BOUNCED_DATASET_WORKING_DIR)\n",
    "        except zipfile.error as e:\n",
    "            pass\n",
    "\n",
    "with zipfile.ZipFile(TEST_DATASET_ZIP_DIR, \"r\") as zip_obj:\n",
    "    for member in tqdm(zip_obj.infolist(), desc=\"Extracting \"):\n",
    "        try:\n",
    "            zip_obj.extract(member, TEST_DATASET_WORKING_DIR)\n",
    "        except zipfile.error as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:34:37.692083Z",
     "start_time": "2022-02-27T08:34:37.689125Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"After zip extraction:\")\n",
    "print(os.listdir(BOUNCED_DATASET_WORKING_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:34:40.367407Z",
     "start_time": "2022-02-27T08:34:40.363761Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(os.listdir(DATA_ROOT))\n",
    "print()\n",
    "print(os.listdir(TEST_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:34:47.717816Z",
     "start_time": "2022-02-27T08:34:42.186390Z"
    }
   },
   "outputs": [],
   "source": [
    "classes_subfolders = [f.path for f in os.scandir(DATA_ROOT) if f.is_dir()]\n",
    "\n",
    "max_images_count = -1\n",
    "for moves_folder in classes_subfolders:\n",
    "    if \"say_so_2\" not in moves_folder:\n",
    "        file_list = [f for f in Path(moves_folder).glob(\"**/*\") if f.is_file()]\n",
    "        if len(file_list) > max_images_count:\n",
    "            max_images_count = len(file_list)\n",
    "print(\"Max images count: {}\".format(max_images_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:52:55.117391Z",
     "start_time": "2022-02-27T08:34:47.719439Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for dir_name in [train_dir, val_dir]:\n",
    "    for class_name in class_names:\n",
    "        if class_name != \"say_so_2\":\n",
    "            os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n",
    "\n",
    "for class_name in class_names:\n",
    "    if class_name != \"say_so_2\":\n",
    "        source_dir = os.path.join(DATA_ROOT, class_name)\n",
    "        for i, file_name in enumerate(tqdm_notebook(os.listdir(source_dir))):\n",
    "            print(os.path.join(train_dir, class_name))\n",
    "            if i % 6 != 0:\n",
    "                dest_dir = os.path.join(train_dir, class_name)\n",
    "            else:\n",
    "                dest_dir = os.path.join(val_dir, class_name)\n",
    "            shutil.copy(\n",
    "                os.path.join(source_dir, file_name), os.path.join(dest_dir, file_name)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:53:37.479775Z",
     "start_time": "2022-02-27T08:53:36.834048Z"
    }
   },
   "outputs": [],
   "source": [
    "pie_chart_dict = dict([(key, []) for key in class_names])\n",
    "for class_sub in classes_subfolders:\n",
    "    class_in_folder_name = os.path.basename(class_sub)\n",
    "    if class_in_folder_name != \"say_so_2\":\n",
    "        images_count = len(os.listdir(class_sub))\n",
    "        pie_chart_dict[class_in_folder_name] = images_count\n",
    "\n",
    "sorted_dict = {}\n",
    "sorted_keys = sorted(pie_chart_dict, key=pie_chart_dict.get)\n",
    "for w in sorted_keys:\n",
    "    sorted_dict[w] = pie_chart_dict[w]\n",
    "pie_chart_dict = sorted_dict\n",
    "\n",
    "print(len(pie_chart_dict))\n",
    "\n",
    "plt.clf()\n",
    "pie, ax = plt.subplots(figsize=[16, 10])\n",
    "pie.autolayout = True\n",
    "pie_chart_labels = [k for k in pie_chart_dict.keys()]\n",
    "pie_chart_data = [float(v) for v in pie_chart_dict.values()]\n",
    "\n",
    "# winter / cool / coolwarm / Set3 also can be used for cmap\n",
    "theme = plt.get_cmap(\"coolwarm\")\n",
    "ax.set_prop_cycle(\n",
    "    \"color\", [theme(1.0 * i / len(pie_chart_data)) for i in range(len(pie_chart_data))]\n",
    ")\n",
    "\n",
    "explode = [0.1] * len(class_names)\n",
    "wedges, labels, autopct = plt.pie(\n",
    "    x=pie_chart_data,\n",
    "    labels=pie_chart_labels,\n",
    "    autopct=lambda p: f\"{p:.2f}%,\\n{p*sum(pie_chart_data)/100 :.0f} img\",\n",
    "    pctdistance=0.85,\n",
    "    explode=explode,\n",
    "    labeldistance=1.1,\n",
    "    textprops={\"fontsize\": 9, \"color\": \"black\"},\n",
    ")\n",
    "[_.set_fontsize(14) for _ in labels]\n",
    "ax.axis(\"equal\")\n",
    "plt.tight_layout()\n",
    "plt.title(\n",
    "    \"Distribution of images in the dataset\",\n",
    "    fontdict={\n",
    "        \"fontsize\": 20,\n",
    "        \"weight\": \"bold\",\n",
    "    },\n",
    ")\n",
    "\n",
    "plt.savefig(\"./{}/distribution_of_images_in_dataset.png\".format(RESULT_PLOTS_DIR))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Pie(labels=pie_chart_labels, values=pie_chart_data))\n",
    "fig.update_layout(title=\"Distribution of images in the dataset\", template=\"seaborn\")\n",
    "fig.show()\n",
    "fig.write_image(\"./{}/distribution_of_images_in_dataset_2.png\".format(RESULT_PLOTS_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:53:41.490785Z",
     "start_time": "2022-02-27T08:53:41.486776Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# output size of one of the images\n",
    "image = Image.open(\"train/dab_left/00002.png\")\n",
    "width, height = image.size\n",
    "print(\"Source images size: width == {}; height == {}\".format(width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_files = 0\n",
    "num_of_dir = 0\n",
    "for base, dirs, files in os.walk(train_dir):\n",
    "    for directories in dirs:\n",
    "        num_of_dir += 1\n",
    "    for Files in files:\n",
    "        num_of_files += 1\n",
    "\n",
    "print(\"Train images count: {}\".format(num_of_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "\n",
    "class ImgAugTransform:\n",
    "    def __init__(self):\n",
    "        self.aug = seq = iaa.Sequential(\n",
    "            [\n",
    "                iaa.Crop(percent=(0, 0.1)),\n",
    "                iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0, 0.5))),\n",
    "                sometimes(iaa.LinearContrast((0.65, 1.5))),\n",
    "                sometimes(iaa.Multiply((0.8, 1.2), per_channel=0.2)),\n",
    "                sometimes(\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.6, 1.2), \"y\": (0.6, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-20, 20),\n",
    "                        shear=(-5, 5),\n",
    "                    )\n",
    "                ),\n",
    "                iaa.SomeOf(\n",
    "                    (0, 5),\n",
    "                    [\n",
    "                        iaa.OneOf(\n",
    "                            [\n",
    "                                iaa.GaussianBlur((0, 3.0)),\n",
    "                                iaa.AverageBlur(k=(2, 7)),\n",
    "                                iaa.MedianBlur(k=(3, 11)),\n",
    "                            ]\n",
    "                        ),\n",
    "                        iaa.AdditiveGaussianNoise(\n",
    "                            loc=0, scale=(0.0, 0.05 * 255), per_channel=0.5\n",
    "                        ),\n",
    "                        iaa.Invert(0.05, per_channel=True),\n",
    "                        iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
    "                        iaa.LinearContrast((0.5, 2.0), per_channel=0.5),\n",
    "                        iaa.Grayscale(alpha=(0.0, 1.0)),\n",
    "                        sometimes(\n",
    "                            iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)\n",
    "                        ),\n",
    "                        sometimes(\n",
    "                            iaa.OneOf(\n",
    "                                [\n",
    "                                    iaa.EdgeDetect(alpha=(0, 0.7)),\n",
    "                                    iaa.DirectedEdgeDetect(\n",
    "                                        alpha=(0, 0.7), direction=(0.0, 1.0)\n",
    "                                    ),\n",
    "                                ]\n",
    "                            )\n",
    "                        ),\n",
    "                    ],\n",
    "                    random_order=True,\n",
    "                ),\n",
    "            ],\n",
    "            random_order=True,\n",
    "        )\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img).copy()\n",
    "        return np.ascontiguousarray(self.aug.augment_image(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMAGE_CROP_HEIGHT, IMAGE_CROP_WIDTH)),\n",
    "        ImgAugTransform(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "print(\"Train dataloader size: {}\".format(len(train_dataloader)))\n",
    "\n",
    "val_transforms = transforms.Compose(\n",
    "    [transforms.Resize((IMAGE_CROP_HEIGHT, IMAGE_CROP_WIDTH)), transforms.ToTensor()]\n",
    ")\n",
    "val_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "print(\"Validation dataloader size: {}\".format(len(val_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_input_num(input_tensor, title=\"\"):\n",
    "    image = input_tensor.permute(1, 2, 0).numpy()\n",
    "    print(image)\n",
    "\n",
    "\n",
    "X_batch, y_batch = next(iter(train_dataloader))\n",
    "for x_item, y_item in zip(X_batch, y_batch):\n",
    "    show_input_num(x_item, title=class_names[y_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:54:12.858007Z",
     "start_time": "2022-02-27T08:53:46.929887Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_input(input_tensor, title=\"\"):\n",
    "    image = input_tensor.permute(1, 2, 0).numpy()\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    plt.pause(0.001)\n",
    "\n",
    "\n",
    "X_batch, y_batch = next(iter(train_dataloader))\n",
    "\n",
    "for x_item, y_item in zip(X_batch, y_batch):\n",
    "    show_input(x_item, title=class_names[y_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:54:12.863376Z",
     "start_time": "2022-02-27T08:54:12.859988Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Train dataloader len == {}, train dataset len == {}\".format(\n",
    "        len(train_dataloader), len(train_dataset)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training and stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:54:22.990778Z",
     "start_time": "2022-02-27T08:54:22.977703Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, loss, optimizer, scheduler, num_epochs):\n",
    "\n",
    "    train_loss_history, valid_loss_history = [], []\n",
    "    train_accuracy_history, valid_accuracy_history = [], []\n",
    "\n",
    "    result_log_file = open(\"train_model_log.txt\", \"w+\")\n",
    "    result_log_file.truncate(0)\n",
    "    result_log_file.seek(0)\n",
    "\n",
    "    for epoch in range(EPOCHS_COUNT):\n",
    "        epoch_result_str = \"Epoch {}/{}:\".format(epoch + 1, num_epochs)\n",
    "        print(epoch_result_str, file=sys.stdout, flush=True)\n",
    "        print(epoch_result_str, file=result_log_file, flush=True)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"val\", \"train\"]:\n",
    "            if phase == \"train\":\n",
    "                dataloader = train_dataloader\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                dataloader = val_dataloader\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "\n",
    "            predlist = torch.zeros(len(class_names), dtype=torch.long, device=\"cpu\")\n",
    "            lbllist = torch.zeros(len(class_names), dtype=torch.long, device=\"cpu\")\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in tqdm_notebook(dataloader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward and backward\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    preds = model(inputs)\n",
    "                    loss_value = loss(preds, labels)\n",
    "                    preds_class = preds.argmax(dim=1)\n",
    "\n",
    "                    # For confusion matrix\n",
    "                    predlist = torch.cat(\n",
    "                        [predlist, preds_class.view(-1).cpu()]\n",
    "                    )  # Save Prediction\n",
    "                    lbllist = torch.cat([lbllist, labels.view(-1).cpu()])  # Save Truth\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss_value.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss_value.item()\n",
    "                running_acc += (preds_class == labels.data).float().mean()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader)\n",
    "            epoch_acc = running_acc / len(dataloader)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                train_loss_history.append(epoch_loss)\n",
    "                train_accuracy_history.append(epoch_acc)\n",
    "            else:\n",
    "                valid_loss_history.append(epoch_loss)\n",
    "                valid_accuracy_history.append(epoch_acc)\n",
    "\n",
    "            loss_acc_result_str = \"{} Loss: {:.4f} Acc: {:.4f}\".format(\n",
    "                phase, epoch_loss, epoch_acc\n",
    "            )\n",
    "            print(loss_acc_result_str, file=sys.stdout, flush=True)\n",
    "            print(loss_acc_result_str, file=result_log_file, flush=True)\n",
    "\n",
    "            # Build confusion matrix\n",
    "            plt.figure().clear()\n",
    "            plt.cla()\n",
    "            plt.clf()\n",
    "\n",
    "            cf_matrix = confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
    "\n",
    "            df_cm = pd.DataFrame(\n",
    "                cf_matrix,\n",
    "                index=[i for i in class_names],\n",
    "                columns=[i for i in class_names],\n",
    "            )\n",
    "            fig = plt.figure(figsize=(35, 35))\n",
    "\n",
    "            cm = plt.cm.get_cmap(\"GnBu\")\n",
    "            sns.heatmap(\n",
    "                df_cm,\n",
    "                annot=True,\n",
    "                vmin=0.0,\n",
    "                vmax=1.0 * max_images_count,\n",
    "                fmt=\".0f\",  # because we use img count\n",
    "                linewidths=2,\n",
    "                cmap=cm,\n",
    "            )\n",
    "\n",
    "            sns.set(font_scale=1.5)\n",
    "            plt.title(\n",
    "                'Confusion Matrix for {}/{} epoch and \"{}\" phase'.format(\n",
    "                    epoch + 1, EPOCHS_COUNT, phase\n",
    "                ),\n",
    "                fontdict={\n",
    "                    \"fontsize\": 20,\n",
    "                    \"weight\": \"bold\",\n",
    "                },\n",
    "            )\n",
    "\n",
    "            plt.xlabel(\"prediction\", fontsize=16)\n",
    "            plt.ylabel(\"label (ground truth)\", fontsize=16)\n",
    "\n",
    "            plt.savefig(\n",
    "                \"./{}/{}/epoch_{:04d}_phase_{}.png\".format(\n",
    "                    RESULT_PLOTS_DIR, confusion_matrix_plots_dir, epoch + 1, phase\n",
    "                )\n",
    "            )\n",
    "\n",
    "            plt.close()\n",
    "\n",
    "    result_log_file.close()\n",
    "\n",
    "    return (\n",
    "        model,\n",
    "        train_loss_history,\n",
    "        valid_loss_history,\n",
    "        train_accuracy_history,\n",
    "        valid_accuracy_history,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:54:38.706237Z",
     "start_time": "2022-02-27T08:54:38.542528Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "model.classifier = torch.nn.Linear(\n",
    "    in_features=model.classifier[1].in_features, out_features=len(class_names)\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:54:40.768955Z",
     "start_time": "2022-02-27T08:54:40.762931Z"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:50:23.822736Z",
     "start_time": "2022-02-27T08:54:44.920949Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    model,\n",
    "    train_loss_history,\n",
    "    valid_loss_history,\n",
    "    train_accuracy_history,\n",
    "    valid_accuracy_history,\n",
    ") = train_model(model, loss, optimizer, None, num_epochs=EPOCHS_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:50:23.839467Z",
     "start_time": "2022-02-27T09:50:23.828485Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loss_history = torch.tensor(train_loss_history, device=\"cpu\")\n",
    "valid_loss_history = torch.tensor(valid_loss_history, device=\"cpu\")\n",
    "train_accuracy_history = torch.tensor(train_accuracy_history, device=\"cpu\")\n",
    "valid_accuracy_history = torch.tensor(valid_accuracy_history, device=\"cpu\")\n",
    "dict_data = {\n",
    "    \"Loss Function Train\": train_loss_history,\n",
    "    \"Loss Function Valid\": valid_loss_history,\n",
    "    \"Accuracy Train\": train_accuracy_history,\n",
    "    \"Accuracy Valid\": valid_accuracy_history,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:50:23.847648Z",
     "start_time": "2022-02-27T09:50:23.840783Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame.from_dict(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:50:23.855844Z",
     "start_time": "2022-02-27T09:50:23.849292Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_plot(data):\n",
    "\n",
    "    result_plots_dir = \"plots\"\n",
    "    result_plots_dir_check = \"./{}\".format(result_plots_dir)\n",
    "    if not os.path.isdir(result_plots_dir_check):\n",
    "        os.makedirs(result_plots_dir_check)\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    loss_names = data.columns[:2]\n",
    "    accuracy_names = data.columns[2:]\n",
    "    legend_names = [\"Train\", \"Valid\"]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    for i, j, k in zip(loss_names, accuracy_names, legend_names):\n",
    "\n",
    "        ax[0].plot(data[i].values, label=k)\n",
    "        ax[1].plot(data[j].values, label=k)\n",
    "\n",
    "    for i, j in enumerate([\"Loss\", \"Accuracy\"]):\n",
    "\n",
    "        ax[i].set_title(f\"{j} Loss Plot\", fontsize=14)\n",
    "        ax[i].set_xlabel(\"Epoch\", fontsize=12)\n",
    "        ax[i].set_ylabel(f\"{j} Loss Function Value\", fontsize=12)\n",
    "        ax[i].legend()\n",
    "\n",
    "    fig.suptitle(\"Result of Model Training\", fontsize=18)\n",
    "    plt.savefig(\"./{}/result_of_model_training.png\".format(result_plots_dir))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:50:24.387844Z",
     "start_time": "2022-02-27T09:50:23.857072Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_plot(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:50:24.586659Z",
     "start_time": "2022-02-27T09:50:24.440298Z"
    }
   },
   "outputs": [],
   "source": [
    "# All information about model\n",
    "summary(model)\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 256, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T10:19:15.084677Z",
     "start_time": "2022-02-27T10:19:15.074142Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path = self.imgs[index][0]\n",
    "        tuple_with_path = original_tuple + (path,)\n",
    "        return tuple_with_path\n",
    "\n",
    "\n",
    "test_dataset = ImageFolderWithPaths(TEST_DIR, val_transforms)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T10:19:35.225708Z",
     "start_time": "2022-02-27T10:19:30.049830Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_predictions = []\n",
    "test_img_paths = []\n",
    "for inputs, labels, paths in tqdm_notebook(test_dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "        preds = model(inputs)\n",
    "    test_predictions.append(\n",
    "        torch.nn.functional.softmax(preds, dim=1)[:, 1].data.cpu().numpy()\n",
    "    )\n",
    "    test_img_paths.extend(paths)\n",
    "\n",
    "test_predictions = np.concatenate(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T10:19:40.740977Z",
     "start_time": "2022-02-27T10:19:40.735331Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame.from_dict(\n",
    "    {\"id\": test_img_paths, \"label\": test_predictions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T10:19:47.422216Z",
     "start_time": "2022-02-27T10:19:47.398973Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"./{}.csv\".format(SUMBISSION_FILE_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T10:19:49.641771Z",
     "start_time": "2022-02-27T10:19:49.572203Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"./{}.pt\".format(MODEL_SAVE_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to the tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T15:37:11.289803Z",
     "start_time": "2022-02-27T15:37:08.757523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input to the model\n",
    "dummy_input = torch.randn(1, 3, IMAGE_CROP_HEIGHT, IMAGE_CROP_WIDTH, requires_grad=True)\n",
    "dummy_input = dummy_input.to(device)\n",
    "\n",
    "torch_out = model(dummy_input)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    model,  # model being run\n",
    "    dummy_input,  # model input\n",
    "    \"./{}.onnx\".format(MODEL_SAVE_NAME),\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    export_params=True,  # store the trained parameter weights inside the model file\n",
    "    opset_version=10,  # the ONNX version to export the model to\n",
    "    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T17:15:38.745068Z",
     "start_time": "2022-02-27T17:15:38.729006Z"
    }
   },
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"./{}.onnx\".format(MODEL_SAVE_NAME))\n",
    "try:\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "except onnx.checker.ValidationError as e:\n",
    "    print(\"The model is invalid: %s\" % e)\n",
    "else:\n",
    "    print(\"The model is valid!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep = prepare(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep.export_graph(PB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = tf_rep.inputs\n",
    "output_nodes = tf_rep.outputs\n",
    "\n",
    "print(\"The names of the input nodes are: {}\".format(input_nodes))\n",
    "print(\"The names of the output nodes are: {}\".format(output_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(PB_PATH)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(TF_PATH, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diploma_env",
   "language": "python",
   "name": "diploma_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
